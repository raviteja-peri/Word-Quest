wc wd smux protocol specification wdmux smux protocol specification wc working draft july this version httpwwwworgtrwdmux latest public version httpwwwworgtrwdmux authors jim gettys compaq computer corporation visiting scientist wc jg@worg henrik frystyk nielsen wc frystyk@worg copyright   wc mit inria keio  all rights reserved wc liability trademark document use and software licensing rules apply status of this document this is a wc working draft for review by wc members and other interested parties it is a draft document and may be updated replaced or made obsolete by other documents at any time it is inappropriate to use wc working drafts as reference material or to cite them as other than work in progress a list of current wc working drafts is also available this document describes an experimental design for a multiplexing transport intended for but not restricted to use with the web smux has been implemented as part of the httpng project use of this protocol is experimentalat this time and the protocol may change in particular transition strategies to use of smux have not been definitively worked out you have been warned this document is part of a suite of documents describing the httpng design and prototype implementation httpng short and longterm goals wd httpng architectural model wd httpng wire protocol wd the classic web interfaces in httpng wd the mux protocol wd description of the httpng testbed note note since working drafts are subject to frequent change you are advised to reference the above url rather than the urls for working drafts themselves this work is part of the wc httpng activity for current status see httpwwwworgprotocolshttpngactivity please send comments on this specification to wwwhttpngcomments@worg abstract this document defines the experimental multiplexing protocol referred to as smux smux is a session management protocol separating the underlying transport from the upper level application protocols it provides a lightweight communication channel to the application layer by multiplexing data streams on top of a reliable stream oriented transport by supporting coexistence of multiple application level protocols eg http and httpng smux should ease transitions to future web protocols and communications of client applets using private protocols with servers over the same tcp connection as the http conversation contents introduction operation and deadlock avoidance smux header alignment session id allocation session establishment protocol ids graceful release disgraceful release message boundaries flow control control messages remaining issues for discussion closed issues from discussion and email glossary references introduction changes from previous version tried to clarify teminology moved comparison between smux and scptmp to end of the document and extracted a goals section from it key words the key words must must not required shall shall not should should not recommended may and optional in this document are to be interpreted as described in rfc   purpose the internet is suffering from the effects of the http protocol which was designed without understanding of the underlying tcp  transport protocol http opens a tcp connection for each uri  retrieved at a cost of both packets and round trip times rtts and then closes the tcp connection for small http requests these tcp connections have poor performance due to tcp slow start   as well as the round trips required to open and close each tcp connection there are at least three reasons why multiple simultaneous tcp connections have come into widespread use on the internet despite the apparent inefficiencies a client using multiple tcp connections gains a significant advantage in perceived performance by the enduser as it allows for early retrieval of metadata eg size of embedded objects in a page this allows a client to format a page sooner without suffering annoying reformatting of the page clients which open multiple tcp connections in parallel to the same server however could cause self congestion on heavily congested links since packets generated by tcp opens and closes are not themselves congestion controlled the additional tcp opens cause performance problems in the network but a client that opens multiple tcp connections simultaneously to the same server may also receive an unfair bandwidth advantage in the network relative to clients that use a single tcp connection this problem is not solvable at the application level only the network itself can enforce such fairness to keep low bandwidthhigh latency links busy eg dialup lines more than one tcp connection has been necessary since slow start may cause the line to be partially idle the keepalive extension to http is a form of persistent tcp connections but does not work through http proxies and does not take pipelining of requests into account instead a revised version of persistent tcp connections was introduced in http as the default mode of operation http  persistent connections and pipelining  will reduce network traffic and the amount of tcp overhead caused by opening and closing tcp connections however the serialized behavior of http pipelining does not adequately support simultaneous rendering of inlined objects  part of most web pages today nor does it provide suitable fairness between protocol flows or allow for graceful abortion of http transactions without closing the tcp connection quite common in http operation persistent connections and pipelining however do not fully address the rendering nor the fairness problems described above a hack solution is possible using http range requests however this approach does not for example allow a server to send just the metadata contained in embedded object before sending the object itself nor does it solve the tcp connection abort problem current tcp implementations do not share congestion information across multiple simultaneous tcp connections between two peers which increases the overhead of opening new tcp connections we expect that transactional tcp  and sharing of congestion information in tcp control blocks  will improve tcp performance by using less rtts and better congestion behavior making it more suitable for http transactions the solution to these problems requires two actions either by itself will not entirely discourage opening multiple tcp connections to the same server from a client internet service providers should enable the random early detection red  or other active congestion control algorithms in their routers to ensure bandwidth fairness to clients when the network is congested red also addresses queue length problems observed in routers today development and deployment of a multiplexing protocol for use with http and eventually other protocols so that multiple objects from a web server can be fetched approximately simultaneously over a single tcp connection so that the metadata to objects can be sent to clients without other metadata waiting for the rest of the first object requested this document describes such an experimental multiplexing protocol it is designed to multiplex a tcp connection underneath http so that http itself does not have to change and allow coexistence of multiple protocols eg http and httpng which will ease transitions to future web protocols and communications of client applets using private protocols with servers over the same tcp connection as the http conversation ideas from this design come from simon speros scp   description and from experience from the x window systems protocol design  goals we believe smux meets the following goals unconfirmed service without negotiation or round trips to the server simple design high performance deadlockfree we believe by a credit based flow control scheme allow multiple protocols to be multiplexed over same tcp connection allow connections to be established in either direction enabling callbacks to the session initiator ability to build a full function socket interface above this protocol low overhead preserves alignment in the data stream so that it is easy to use with protocols that marshal their data in a binary form smux protocol operation deadlock scenario multiplexing multiple sessions over a single transport tcp connection introduces a potential deadlock that smux is designed to avoid here is an example of potential deadlock presume that each session is being handled by an independent thread and that memory available to the smux implementation is limited for example on a thin client on a meter reader for the purposes of this example presume the thin client has k bytes of buffer available to its smux implementation and cannot get more the sender of data decides to send as part of a session request syn message k bytes of initial data there are no other senders so all of the data gets transmitted but the thread to deal with the message is blocked and cannot make progress unless smux can buffer all k or  meg or pick your favorite numbers any other sessions data would be blocked behind this initial transmission until and unless smux can read and buffer the data someplace and since it has no buffer available the deadlock occurs many similar but possibly harder to explain deadlocks are possible this example points out that deadlock is possible smux must be able to buffer data independently of the consumers of the data it must also have some way to throttle sessions where the consumer of the data is not responsive in the multiplexing layer in this example prevent the transmission of more than  kbytes of data note that this deadlock is independent of the size of any multiplexing fragment but strictly dependent on availability of buffer space in smux for a particular session deadlock avoidance in smux the receiver makes a promise sends a credit to the transmitter that a certain amount of buffer space is available or at least that it will consume the bytes if not buffer them eg a real time audio protocol where the data is disposed of and the transmitter promises not to send more data than the receiver has promised no more than the credit if these promises are met then smux will not deadlock a smux implementation must maintain and adhere to the credit system or it can deadlock implementations on systems with large amounts of memory eg vm systems may be quite different than ones on thin clients with limited nonvirtual memory it is reasonable on a vm system to hand out credits freely analogous to the virtual socket buffering found in tcp implementations but your implementation must be careful to test its credit mechanisms so that they will inter operate with limited memory systems credit control messages may be sent on sessions that are not active sessions have an initial credit size initial_default_credit of  kb on each session there is a smux control message to set this initial credit to something larger than the default operation and implementation considerations a transmitter must not transmit more data in a fragment than the available credit on the session or it could deadlock an smux implementation must fragment streams when transmitting them into fragments the max_fragment_size a variable which is maintained on currently a per transport tcp connection basis determines the largest possible fragment a sender should ever send to a receiver this determines the maximum latency introduced by a smux layer above and beyond the inherent tcp latencies socket buffering on both sender and receiver and the delaybandwidth product amount of data that could be in flight at any given instant a client on a low bandwidth link or with limited memory buffering might decide to set the max_fragment_size down to control latency and buffer space required if max_fragment_size is set to zero the transmitter is left to determine the fragment size and may take into account application protocol knowledge eg a smux implementation for http might send fragments of the metadata of embedded objects or the next phase of a progressive image format which it only knows an implementation should honor the max_fragment_size as it transmits data if it has been set by the receiver an smux implementation that does not have explicit knowledge or experience of good fragment sizes might use these guidelines as a starting point the path_mtu of the tcp connection minus the size of the tcp and ip headers remember that ipv may have longer headers and  bytes for an xmux header if this information is available  the mss of the tcp connection if the path_mtu is not available in either case you probably want to subtract  bytes to make sure a smux header can be added without forcing another tcp segment this would result in fragmentation roughly similar to tcp segmentation over multiple tcp connections an implementation should round robin between sessions with data to send in some fashion to avoid starving sessions or allowing a single thread to monopolize the tcp connection exact details of such behavior is left to the implementation to achieve highest bandwidth and lowest overhead smux behavior credits should be handed out in reasonably large chunks tcp implementations typically send an ack message on every other packet and it is very hard to arrange to piggyback acks on data segments in implementations therefore for smux to have reasonably low overhead credits should be handed out in some significant multiple  or more times larger than the  bytes represented by two packets on an ethernet the outstanding credit balance across active sessions will also have to be larger than the bandwidthdelay product of the tcp connection if smux is not to become a limit on tcp transport performance both of these arguments indicate that outstanding credits in many implementations should be k bytes or more implementations should piggyback credit messages on data packets where possible to avoid unneeded packets on the wire a careful implementation in which both ends of the tcp connection are regularly sending some payload should be able to avoid sending extra packets on the network if necessary we could add in a future version fragmentation control messages to do some bandwidth allocation but for now we are not bothering smux header smux headers are always in big endian byte order if people want we could expand out the union below on a control message type basis eg the way the c bindings to x events were written out for this draft im not doing so define mux_control xdefine mux_syn xdefine mux_fin xdefine mux_rst xdefine mux_push xdefine mux_session xffdefine mux_long_length xffdefine mux_length xfffftypedef unsigned int flagbitstruct wmux_hdr  union  struct  unsigned int session_id   flagbit control   flagbit syn   flagbit fin   flagbit rst   flagbit push   flagbit long_length   unsigned int fragment_size   int long_fragment_size    only present if long_length is set   data_hdr struct  unsigned int session_id   flagbit control   unsigned int control_code   flagbit long_length   unsigned int fragment_size   int long_fragment_size    only present if long_length is set   control_message  contents the fragment_size is always the size in bytes of the fragment excluding the smux header and any padding alignment smux headers are always at least  bit aligned to find the next smux header take the fragment_size and round up to the next  bit boundary transmitters may insert noop control messages to force  bit alignment of the protocol stream long fragments a smux header with the long_length bit set must use the  bits following the smux header the long_fragment_size field for the value of the fragment_size field for whatever purpose the fragment_size field is being used for atoms atoms are integers that are used as shorthand names for strings which are defined using the internatom control message atoms are only used as protocol ids in this version of smux though they might be used for other purposes in future versions since the atom might be redefined at any time it is not safe to use an atom unless you have defined it ie you cannot use atoms defined by the other end of a mux connection atoms are therefore not unique values and only make sense in the context of a particular direction of a particular mux connection this restriction is to avoid having to define some protocol for deallocating atoms with any round trip overhead that would likely imply strings are defined to be utf encoded unicode strings note that an ascii string is valid utf the definition of structure of these strings is outside of the scope of this document though we expect they will often be uris naming a protocol or stack of protocols atoms always have values between x and xff a maximum of  atoms can be defined strings used for protocol ids must be uris  protocol ids the protocol used by a session is identified by a protocol id which can either be an iana port number or an atom to allow higher layers to stack protocols eg http on top of deflate compression on top of tcp to identify the protocol or protocol stack in use so that application firewall relays can perform sanity checking and policy enforcement on the multiplexed protocols  in the simplest case a protocol id is just a value in the range of xffff and specifies the tcp port number xxffff or udp port number xxffff of the protocol per the iana port number registry  firewall proxies can presume that the bytes should conform to that protocol protocol ids above xfffff are atoms the scheme name of the uri indicates the protocol family being used session id allocation each session is allocated a session identifier session identifiers below  and  are reserved for future use session ids allocated by initiator of the transport tcp connection are even those allocated by the receiver of the transport connection odd proxies that do not understand messages of reserved session ids should forward them unchanged a session identifier must only be deallocated and potentially reused by new sessions when a session is fully closed in both directions session establishment to establish a new session the initiating end sends a syn message allocating a free session number out of its address space a session is established by setting the syn bit in the first message sent on that session the session is specified by the session_id field the fragment_size field is interpreted as the protocol id of the session as discussed above the receiver must either open the reverse path of that session send a syn message or it must send a fin message to indicate that the reverse path is not going to be used further or send a rst message to indicate an error this enables the initiator of a session to know when it is safe to reuse that session id graceful release a session is ended by sending a fragment with the fin bit set each end of a mux connection may be closed independently mux uses a halfclose mechanism like tcp to close data flowing in each direction in a session after sending a fin fragment the sender must not send any more payload in that direction disgraceful release a session may be terminated by sending a message with the rst bit set all pending data for that session should be discarded no such protocol errors detected by the receiver of a new session are signaled to the originator on session creation by sending a message with the rst bit set same as in tcp the payload of the fragment containing the rst bit contains the null terminated string containing the uri of an error message note that content negotiation makes this message potentially multilingual followed by a null terminated utf string containing the reason for the reset in case the uri is not accessable message boundaries a message boundary is marked by sending a message with the push bit set the boundary is set between the last octet in this message including that octet and the first byte of a subsequent message this differs slightly from tcp as push can be reliably used as a record mark flow control flow control is determined by a simple credit scheme described above by using the addcredits control message defined below fragments transmitted must never exceed the outstanding credit for that session the initial outstanding credit for a session is kbytes end points one of the major design goals of smux is to allow callbacks to objects in the process that initiated the transport tcp connection without requiring additional tcp connections with the overhead in both machine resources and time that this would cause or the problems with tcp connection establishment through firewalls the defineendpoint control message allows one to advertize that a particular set of uris are reachable over the transport tcp connection control messages the control bit of the smux header is always set in a control message control messages can be sent on any session even sessions that are not yet open the control_code reuses the syn fin rst and push bits of the smux header the control_code of the control message determines the control message type any unused data in a control message must be ignored the revised version of smux means that a session creation costs  bytes a control message with syn set and with the protocol id in the message therefore the first fragment of payload has a total overhead of  bytes this is presuming using an iana based protocol rather than a named protocol this is the same as the previous version though it means two messages rather than one the individual control message types are listed below code name dir description  internatom both the session_id is used as the atom to be defined offset by x so a value of  is defining id x the fragment_size field is the length of the utf encoded string the fragment itself contains the string to be interned this allows the interning of  strings is this enough  defineendpoint both the session_id is ignored the fragment_size is interpreted as the protocol id naming an endpoint actually available on this transport tcp connection this enables a single transport tcp connection to be used for callbacks or to advertise that a protocol endpoint can be reached to the process on the other end of the transport tcp connection whether this relative uri naming can be used depends upon the scheme of the uri  which defines its structure for example a firewall proxy might advertize just http for the proxy claiming it can be used to contact any http protocol object anywhere or httpfoocombar to indicate that any object below that point in the uri space on the server foocom may be reached by this tcp connection a client might advertize that httpmyhostcom is available via this transport tcp connection  setmss both this sets a limit on fragment sizes below the outstanding credit limit the session_id must be zero the fragment_size field is used as max_fragment_size the largest fragment that be sent on any session on this transport tcp connection a max_fragment_size of zero means there is no limit on the fragment size allowed for this session  addcredit rt the session_id specifies the session the fragment_size specifies the flow control credit granted to be added to the current outstanding credit balance a value of zero indicates no limit on how much data may be sent on this session  setdefaultcredit rt the session_id must be zero the fragment_size field is used as to set the initial default credit limit for any incoming mux connections over this transport tcp connection ie it is short hand for sending a series of addcredit messages for each session id  noop both this control message is defined to perform no function any data in the payload should be ignored   undefined reserved for future use must be ignored if not understood and forwarded by any proxies the fragment_size is always used for the length of the control message and any data for the control message will be in the payload of the control message to allow proxies to be able to forward future control messages remaining issues for discussion when can mux be used what are the appropriate strategies for determining if the simple multiplexing protocol can be used name server hack upgrade in http remember that previous upgrade to use mux worked comparison with scp tmp note that tip transaction internet protocol  defines a version of scp called tmp  goals unconfirmed service without negotiation scp allows data to be sent with the session establishment the recipient does not confirm successful mux connection establishment but may reject unsuccessful attempts this simplifies the design of the protocol and removes the latency required for a confirmed operation simple design performance where critical there are five issues that make scp tmp inadequate for our use scp can deadlock unless unlimited amounts of memory is available it has no provision for multiplexing multiple protocols over the same transport tcp connection essential for graceful transition without dependency on the currently incomplete ng design and to allow other uses which could use the same multiplexed connection eg applet communication with serverlets scps  byte overhead is not reasonable most of the time smux uses four bytes in the default case the design below permits an  byte header if you care to preserve  bit alignment at the cost of bytes in practice there seems few data formats or architectures that actually require more than  bit alignment without some form of flow control infinite buffering in clients receivers would be required alignment is preserved in the data stream this allows compact high speed unmarshalling code in implementations of binary protocols without extra data copies which in such protocols can be significant overhead scp syn in version  requires a second message which costs a round trip so far smux is similar to scp there are some important differences deadlockfree we believe by a credit based flow control scheme allow multiple protocols to be multiplexed over same tcp connection not available in scp lower overhead than scp while preserving data alignment very important for binary protocol marshaling code ability to build a full function socket interface above this protocol smux avoids the syn round trip of scp v by session ids being allocated in independent address spaces this also avoids many of the state transitions of scp simplifying the protocol greatly other comment on scp scp has  sessions which seems highly excessive and reserves  of them for future use closed issues from discussion and mail some of the comments below allude to previous versions of the specification and may not make sense in the context of the current version flow control priority vs credit schemes henrik and i have convinced ourselves there are fundamental differences between a priority scheme and the credit scheme in this draft they interact quite differently with tcp and priority schemes have no way to limit the total amount of data being transmitted though priority schemes are better matched to what the web wants weve decided at least for now to defer any priority schemes to higher level protocols stacking protocols and transports stacks ilu  style protocol stacks are a good thing there have been too many worries about the birthday problem for people to be comfortable with bill janssens hashing schemes see henrik frystyk nielsen and robert thaus mail on this topic we tried putting this directly in mux in a previous version and experience shows that it didnt really help an implementer in particular bill janssen while implementing ilu this version has just the name of the protocol and it is left to others to implement any stacking eg ilu we believe the name of the protocol is necessary if smux is ever to be used with firewalls application level firewall relays need the protocol information to sanity check the protocol being relayed application level relays are considered much more secure than just punching holes in the firewall for particular protocol families which small organizations often find sufficient as the relay can sanity check the protocol stream and enable better policy decisions for example to forbid certain datatypes in http to transit a firewall large organizations and large targets typically only run application level proxies byte usage wasting bytes in general and in particular at tcp connection establishment for a multiplexing transport must be avoided there are several reasons for this if the initial segment is too long a network round trip will be lost to tcp slow start so bytes near the beginning of a conversation may be much more precious than bytes later in the conversation once slow start overhead has been paid if the first segment is too long you fall off a cliff directly affects user perceived response no cleverness of later packing and batching of request can get the time back each goes directly to perceived latency when a user talks to the server for the first time so there is more than the usual tension between generality vs performance performance analysis human perception is about  milliseconds if much more than this the user perceives delay at  k baud one byte uncompressed costs  milliseco nds ignoring modem latencies on an airplane via telephone today you get a munificent  baud which is x slower cellular modems transmitting data cdpd as i understand it will give us around kbaud when deployed so basic multiplexing @  byte overhead costs   milliseconds on common modems this means basic overhead is small vs human perception for most low speed situations a good position to be in on cmux onnection open with above protocol we send  bytes in the setup message and then must open a session requiring at least  bytes more  bytes   milliseconds at k not  bit aligned and  bytes costs of order  milliseconds ugh maybe a setup message isnt a good idea other uses eg security can be dealt with by a control message multiple protocols over one smux we want to smux multiple protocols simultaneously over the same transport tcp connection so we need to know what protocol is in use with each session so the demultipexor can hand the data to the right person eg sunrpc and dcercp simultaneously there are two obvious ways i can see to do this a send a control message when a session is first used indicating the protocol disadvantage costs probably  bytes to do so  smux overhead and  byte message and destroys potential  bit alignment b if syn is set indicating new session then steal mux_length field to indicate protocol in use on that session overhead  bytes for the smux header used just to establish the session opinions mine is that b is better than a answer b is the adopted strategy priority for a given stream priority will affect which session is handled when multiplexing data sending the priority on every block is unneeded and would waste bytes there is one case in which priority might be useful at an intermediate proxy relaying sessions and maybe remultiplexing them if so it should be sent only when sessions are established or changed changes can be handled by a control message opinions a priority field can be hacked into the length field with the protocol field using b above so the question is is it important to send priority at all in this smux protocol or should priority control if needed be a control message  control message answer not in this protocol opens pandoras box with remultiplexors which could have denial of service attacks setup message is any setup message needed i dont think it is and initial bytes are precious see performance discussion above and it complicates trivial use if we move the byte order flag to the smux header and use control messages if other information needs to be sent we can dispense with it and the layer is simpler this is my current position and unless someone objects with reasons ill nuke it in the next version of this document answer not needed nuked byte order flags while higher layer protocols using host dependent byte order can be a performan ce win when sending larger objects such as arrays of data the overhead at this layer isnt much and may not be worth bothering with worst case naive code would be four memory reads and  shift overheadpayload smart code is one load and appropriate shifts etc opinions im still leaning toward swapping bytes here but there are other examples of byte load and shift particularly slow on alpha but not much of an issue on other systems answer not sufficient performance gain at smux level to be worth doing defined as le byte order for smux headers error handling there are several error conditions probably best reported via control messages from server no such protocol some sort of serial number should be reported i suppose this serial number can be implicit as in x bad message some combinations of flag bits are not legal priority if it exists any others any twists to worry about answer only error that can occur is no such protocol given no priority in the base protocol may still be some unresolved issues here around christma s tree message all bits turned on length field any reason to believe that the  bit length field for a single payload is inadequate i dont think so and i live on an alpha answer  bit extended length field for a single fragment is sufficient compression does there need to be a bit saying the payload is compressed to avoid explosion of protocol types answer yes introduction of control message to allow specification of transport stacks achieves this stacks i think that we should be able to multiplex any tcp udp or ip protocol internet protocol numbers are  bit fields so we need  bits for tcp one bit to distinguish tcp and udp and one bit more we can use for ip protocol numbers and address space we can allocate privately this argues for an  bit length field to allow for this reuse   bit length field    bit session field    control bits    long length bit  the last bit is used to define control messages which reuse the syn fin rst and push bits as a control_code to define the control message there are escapes both by undefined control codes and by the reservation of two sessions for further use if there needs to be further extensions the spec above reflects this alignment back to alignment if we demand  byte alignment for all requests that do not end up naturally aligned we waste bytes two bytes are wasted on average at kbaud the overhead for protocols that do not pad up would on mean be  bytes or ms rather than  bytes or   ms presuming even distributions of length note that this does not effect initial request latency time to get first url and is therefore less critical than elsewhere i have one related worry it can sometimes be painful to get padding bytes at the end of a buffer ive heard of people losing by having data right up to the end of a page so implementations are living slightly dangerous ly if they presume they can send the padding bytes by sending the   or  bytes after the buffer rather than an independent write to the os for padding bytes alternatively the buffer alignment requirement can be satisfied by implementations remembering how many pad bytes have to be sent and adjusting the beginning address of the subsequent write by that many bytes before the buffer where the smux header has been put am i being unnecessarily paranoid opinion i believe alignment of fragments in general is a good thing and will simplify both the smux transport and protocols at higher levels if they can make this presumption in their implementations so i believe this overhead is worth the cost if you want to do better and save these bytes then start building an application specific compression scheme if not please make your case control bits are the four bits defined in simons flags field what we need are there any others answer no more bits than we need current protocol doesnt use as many ive ended back at the original bits specified rather than the smaller set suggested by bill janssen this enables full emulation of all the details of a socket interface which would not otherwise be possible see details around tcp and socket handling discussed in books like tcpip illustrated by w richard stevens am i all wet opinion i believe that we should do this control messages question do we wantneed a short control message right now the out for extensibility are control messages sent in the reserved and as yet unspecified  control session this requires a minimum of  bytes on the wire we could steal the last available bit and allow for a  byte short control message that would have  bits of payload opinion flow control needs it protocoltransport stacks need it document above now defines some control messages simplicity of default behavior the above specification allows for someone who just wants to smux a single protocol to entirely ignore protocol ids glossary to be supplied references j postel transmission control protocol rfc  network information center sri international september  j postel tcp and ip bake off rfc  september  j mogul s deering path mtu discovery rfc  decwrl stanford university november  t bernerslee universal resource identifiers in www a unifying syntax for the expression of names and addresses of objects on the network as used in the worldwide web rfc  cern june  r braden ttcp  tcp extensions for transactions functional specification rfc  uscisi july  r fielding relative uniform resource locators rfc  uc irvine june  t bernerslee r fielding h frystyk hypertext transfer protocol  http rfc  wcmit uc irvine wcmit may  r fielding j gettys j c mogul h frystyk t bernerslee hypertext transfer protocol  http rfc  uc irvine dec wcmit dec wcmit wcmit january  s bradner key words for use in rfcs to indicate requirement levels rfc  harvard university march  j touch tcp control block interdependence rfc  april  w stevens tcp slow start congestion avoidance fast retransmit and fast recovery algorithms rfc  january  v jacobson congestion avoidance and control proceedings of sigcomm  h frystyk nielsen j gettys a bairdsmith e prudhommeaux h w lie and c lilley network performance effects of http css and png proceedings of sigcomm  s floyd and v jacobson random early detection gateways for congestion avoidance ieeeacm trans on networking vol  no  aug  rwscheifler j gettys the x window system acm transactions on graphics   special issue on user interface software   v paxson growth trends in widearea tcp connections ieee network vol  no  pp  july  s spero session control protocol version  s spero session control protocol version  keywords and port numbers are maintained by iana in the portnumbers registry keywords and protocol numbers are maintained by iana in the protocolnumbers registry w richard stevens tcpip illustrated volume  addisonwesley  bernerslee t fielding r masinter l uniform resource identifiers uri generic syntax and semantics work in progress of the ietf november  j lyon k evans j klein transaction internet protocol version  work in progress of the transaction internet protocol working group november  b janssen m spreitzer interlanguage unification in particular see the manual section on protocols and transports @ id wdmuxhtmlv    frystyk exp 